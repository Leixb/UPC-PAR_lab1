% vim: spell:spelllang=en:
\input{preamble}

\renewcommand\theadfont{\bfseries}

\title{
    PAR Laboratory Assignment\\
    Lab 1: Experimental setup and tools
}

\author{
    par2109:
    Aleix Boné,
    Alex Herrero
}

\date{
    Spring 2019-20
}

\begin{document}

% https://github.com/carlotacb/PAR-Laboratoris/blob/master/LAB%201/Deliverable.pdf


%After the last session for this laboratory assignment, and before starting the
%next one, you will have to deliver a report in PDF format (other formats will
%not be accepted) describing the results and conclusions that you have obtained
%when doing the assignment. As part of the document, you will have to include
%any code fragment, figure or plot you need to support your explanations. Your
%professor will open the assignment at the Raco website and set the appropriate
%delivery dates for the delivery. Only one file has to be submitted per group
%through the Raco website.
%
%Important: In the front cover of the document, please clearly state the name of
%all components of the group, the identifier of the group (username parXXYY),
%title of the assignment, date, academic

\maketitle

\pagebreak
\tableofcontents
\pagebreak
\pagenumbering{arabic} 

\section{Node architecture and memory}%
\label{sec:node_architecture_and_memory}

%Describe the architecture of the boada server. To accompany your description,
%you should refer to the following table summarising the relevant architectural
%characteristics of the different node types available:

The boada server consists of 8 different nodes with different processors. As we can see in
the table~\ref{tab:node_arch_and_mem} there are 3 different architectures with slight variations
\texttt{boada-1 to boada-4} have the same number of sockets(2), cores(6) and threads per core (2), which adds up to a total of 24 threads.

\texttt{boada-5} has the same number of sockets, threads and cores as the previous \texttt{boadas} but with higher Maximum core frequency and a much larger shared cache size and Main memory.
The output of \texttt{lstopo} also shows us that it has 4 \texttt{GPUs}.

\texttt{boada-6 to boada-8} have 8 cores per socket but only one thread per core (amounting to 16 threads instead of the 24 of the other nodes) and a much lower clock frequency. However it has the
highest last-level cache size.

\begin{table}[H]%
    \label{tab:node_arch_and_mem}
    \centering
    %\caption{caption}
    \begin{tabular}{lrrr}

    \toprule
        & \texttt{boada 1 to 4} & \texttt{boada 5} & \texttt{boada 6 to 8} \\
    \midrule
        Number of sockets per node          & 2        & 2        & 2        \\
        Number of cores per socket          & 6        & 6        & 8        \\
        Number of threads per core          & 2        & 2        & 1        \\
        Maximum core frequency              & 2395 MHz & 2600 MHz & 1700 MHz \\
    \addlinespace[1em]
        L1-I cache size (per-core)          & 32K      & 32K      & 32K      \\
        L1-D cache size (per-core)          & 32K      & 32K      & 32K      \\
        L2 cache size (per-core)            & 256K     & 256K     & 256K     \\
        Last-level cache size (per-socket)  & 12288K   & 15360K   & 20480K   \\
    \addlinespace[1em]
        Main memory size (per socket)       & 12 Gb    & 31 Gb    & 16 Gb    \\
        Main memory size (per node)         & 23 Gb    & 63 Gb    & 31 Gb    \\
    \bottomrule

    \end{tabular}
\end{table}

%Also include in the description the architectural diagram for one of the nodes
%boada-1 to boada-4 as obtained when using the lstopo command. Appropriately
%comment whatever you consider appropriate.

In figure~\ref{fig:arch_boada1} we can see the data from table~\ref{tab:node_arch_and_mem} corresponding
to \texttt{boada-1}. The cache L3 is shared between the cores of each socket.
 while the others are local to each core. There is no shared memory between the sockets.

\begin{figure}[H]%
    \caption{Architectural diagram for \texttt{boada-1}}%
    \label{fig:arch_boada1}
    \centering
    \includegraphics[width=\textwidth]{./data/map-boada-1.pdf}
\end{figure}


\section{Strong vs.\ weak scalability}%
\label{sec:strong_vs_weak_scalability}

%Briefly explain what strong and weak scalability refer to. Exemplify your
%explanation using the execution time and speed–up plots that you obtained for
%pi omp.c. Reason about the results obtained.

In strong scalability  the  number  of  threads  is  changed  with  a  fixed  problem  size.   In  this  case parallelism is used to reduce the execution time of the program.

In weak scalability the problem size is proportional to the number of threads. In this case parallelism is used to increase the problem size for which the program is execute

\begin{figure}[H]%
    \caption{Strong scalability}%
    \label{fig:strong}
    \centering
    \includegraphics[width=\textwidth]{./data/pi/pi_omp-1000000000-1-12-3-strong-boada-2.pdf}
\end{figure}

In strong scalability, as we can observe in figure~\ref{fig:strong}, time decreases as we increase the number of threads and therefore the speedup almost increases linearly. Except in the case we use 12 threads that time and speedup increase because there are threads without doing useful work.

\begin{figure}[H]%
    \caption{Weak scalability}%
    \label{fig:weak}
    \centering
    \includegraphics[width=\textwidth]{./data/pi/pi_omp-100000000-1-12-3-weak-boada-3.pdf}
\end{figure}

In the other hand, in weak scalability (figure~\ref{fig:weak}) we can see that the parallel efficiency remains close to the ideal vale of 1 slowly decreasing and dips at 11 threads although for 12 it gets 



%TODO: razonar sobre los resultados obtenidos


\section{Analysis of task decompositions for \emph{3DFFT}}%
\label{sec:analysis_of_task_decompositions_for_3dfft}

%In this part of the report you should summarise the main conclusions from the
%analysis of task decompositions for the 3DFFT program. Backup your conclusions
%with the following table properly filled in with the information obtained in
%the laboratory session for the initial and different versions generated

\begin{table}[H]%
    \label{tab:parallelism}
    \centering
    %\caption{caption}
    \begin{tabular}{cccc}
    \toprule
    \thead{Version} & $T_1$ & $T_\infty$ & \thead{Parallelism} \\
    \midrule
    seq     & 639780001 &  639780001 & 1 \\ % todas las a seran la misma (o deberían)
    v1      & 639780001 &  639707001 & 1.000114115 \\ % c = a/b
    v2      & 639780001 & 361190001 & 1.771311496 \\
    v3      & 639780001 & 154438001 & 4.142633269 \\
    v4      & 639780001 & 64102001 & 9.98065569 \\
    v5      & 639780001 & b & c \\
    \bottomrule
    \end{tabular}
\end{table}

%TODO: completar tabla y sacar conclusiones

%For versions v4 and v5 of 3dfft tar.c perform an analysis of the potential
%strong scalability that is expected. For that include a plot with the
%execution time and/or speedup when using 1, 2, 4, 8, 16 and 32 processors, as
%reported by the simulation module inside Tareador. You should also include the
%relevant(s) part(s) of the code that help the reader to understand why v5 is
%able to scale to a higher number of processors compared to v4, capturing the
%task dependence graphs that are obtained with Tareador.

\begin{figure}[H]%
    \caption{Execution time of v4 with 1 processor}%
    \label{fig:plot_v4_01}
    \centering
    \includegraphics[width=\textwidth]{./data/3dfft_/plots/v4_01.png}
\end{figure}

\begin{figure}[H]%
    \caption{Execution time of v4 with 2 processors}%
    \label{fig:plot_v4_02}
    \centering
    \includegraphics[width=\textwidth]{./data/3dfft_/plots/v4_02.png}
\end{figure}

\begin{figure}[H]%
    \caption{Execution time of v4 with 4 processors}%
    \label{fig:plot_v4_04}
    \centering
    \includegraphics[width=\textwidth]{./data/3dfft_/plots/v4_04.png}
\end{figure}

\begin{figure}[H]%
    \caption{Execution time of v4 with 8 processors}%
    \label{fig:plot_v4_08}
    \centering
    \includegraphics[width=\textwidth]{./data/3dfft_/plots/v4_08.png}
\end{figure}

\begin{figure}[H]%
    \caption{Execution time of v4 with 16 processors}%
    \label{fig:plot_v4_16}
    \centering
    \includegraphics[width=\textwidth]{./data/3dfft_/plots/v4_16.png}
\end{figure}

\begin{figure}[H]%
    \caption{Execution time of v4 with 32 processors}%
    \label{fig:plot_v4_32}
    \centering
    \includegraphics[width=\textwidth]{./data/3dfft_/plots/v4_32.png}
\end{figure}

\begin{figure}[H]%
    \caption{Execution time of v5 with 1 processor}%
    \label{fig:plot_v5_01}
    \centering
    \includegraphics[width=\textwidth]{./data/3dfft_/plots/v5_01.png}
\end{figure}

\begin{figure}[H]%
    \caption{Execution time of v5 with 2 processors}%
    \label{fig:plot_v5_02}
    \centering
    \includegraphics[width=\textwidth]{./data/3dfft_/plots/v5_02.png}
\end{figure}

\begin{figure}[H]%
    \caption{Execution time of v5 with 4 processors}%
    \label{fig:plot_v5_04}
    \centering
    \includegraphics[width=\textwidth]{./data/3dfft_/plots/v5_04.png}
\end{figure}

\begin{figure}[H]%
    \caption{Execution time of v5 with 8 processors}%
    \label{fig:plot_v5_08}
    \centering
    \includegraphics[width=\textwidth]{./data/3dfft_/plots/v5_08.png}
\end{figure}

\begin{figure}[H]%
    \caption{Execution time of v5 with 16 processors}%
    \label{fig:plot_v5_16}
    \centering
    \includegraphics[width=\textwidth]{./data/3dfft_/plots/v5_16.png}
\end{figure}

\begin{figure}[H]%
    \caption{Execution time of v5 with 32 processors}%
    \label{fig:plot_v5_32}
    \centering
    \includegraphics[width=\textwidth]{./data/3dfft_/plots/v5_32.png}
\end{figure}

%TODO: comentar graficos


%TODO: incluir partes del codigo para entender porque v5 blabla mejor que v4


\section{Understanding the parallel execution of \emph{3DFFT}}%
\label{sec:understanding_the_parallel_execution_of_3dfft}

%In this final section of your report you should comment about how did you
%observed with Paraver the parallel performance evolution for the OpenMP
%parallel versions of 3DFFT. Support your explanations with the results reported
%in the following table which you obtained during the laboratory session. It is
%very important that you include the relevant Paraver captures (timelines and
%profiles of the % of time spent in the differentOpenMPstates) to support your
%explanations too.

\begin{table}[H]%
    \label{tab:under_parallelism}
    \centering
    %\caption{caption}
    \begin{tabular}{lrr@{\hskip 2em}rrr}
    \toprule
    \thead{Version} & $\phi$ & $S_\infty$ & $T_1$ & $T_8$ & $S_8$ \\
    \midrule
    initial version in \texttt{3dfft\_omp.c}                & 0.5692 & 2.3211 & 2382.891 ms & 1.469 ms & 1621.58 \\
    new version with improved $\phi$                        & phi & Sinf & t1 & t8 & S8 \\
    final version\footnote{with reduced parallelization overheads}    & phi & Sinf & t1 & t8 & S8 \\
    \bottomrule
    \end{tabular}
\end{table}

%TODO: completar tabla

%TODO: incluir capturas de Paraver

%TODO: comment about how did you observed with Paraver the parallel 
%      performance evolution for the OpenMP parallel versions of 3DFFT.

%Finally you should comment about the (strong) scalability plots (execution time
%and speed–up) that are obtained when varying the number of threads for the
%three parallel versions that you have analysed.

%TODO: incluir plots y comentarlos

\end{document}
